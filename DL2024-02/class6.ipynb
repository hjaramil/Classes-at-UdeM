{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWiKAebTW1lu9yVz7yvOqp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Ejemplo** Sea $A$ la matriz\n","\n","$$A = \\begin{pmatrix} 1 & 1  \\\\ 1 & 0 \\\\ 0 & 1  \\end{pmatrix} .$$\n","\n","Halle la descomposicion SVD de $A$, redondee a 2 lugares decimales.\n","\n","**Solucion**:\n","\n","* Construya $A^* A$ y $A A^*$. Busque la mas pequenha, deje la mas grande para mas tarde, si es que la necesita.\n","\n","* Encuentre los autovalores de $A^* A$ y de $A^* A$, son los mismos pero\n","si $A^* A$, $2 \\times 2$ (tiene 2) y $A A^*$ es $3 \\times 3$, o sea que tiene 3. El truco halla los de $A^*A$ que es $2 \\times 2$ y el otro autovector de la matriz $A A^*$ es 0.\n","* Encuentre los autovectores de $A^* A$ (los $v_i$) y de $A A^*$ (los $u_i$).\n","* Construya $U$ con los autovectores de $A A^*$ y $V$ con los autovectores de $A^* A$. La matriz $\\Sigma$ tiene los autovalores de **mayor a menor**\n","y 0 en todas las otra partes. $\\Sigma$ es de orden es $3 \\times 2$.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"-0gYvpvhhvJy"}},{"cell_type":"markdown","source":["* Existen dos matrices importantes $A^T A$, $A A^T$. Enfoquemonos en la mas pequenha. $A^T A$ es $2 \\times 2$, $A A^T$ es una matrix $3 \\times 3$.\n","\n","$$A^T A = \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 0 & 1\\end{pmatrix}  \n","\\begin{pmatrix} 1& 1 \\\\ 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\n","= \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} .$$\n","\n","* Encontrar autovalores.\n","\n","$$p(\\lambda) = \\begin{vmatrix} 2 - \\lambda & 1 \\\\ 1 & 2 -\\lambda \\end{vmatrix} = (2 - \\lambda)^2 - 1 =4 - 4 \\lambda + \\lambda^2 - 1 = \\lambda^2 - 4 \\lambda + 3  = (\\lambda - 3)(\\lambda -1)=0  .$$\n","pues $\\det (A - \\lambda I)=0$, es que produce los autvalores/vectores.\n","O sea que los autovalores son\n","\n","$$ \\lambda = 3  \\quad , \\quad \\lambda = 1 .$$\n","\n","Encontrar los autovectores.\n","* $\\lambda = 3$.\n","Escribimos la ecuacion $(B - \\lambda I) v = 0$.\n","En este caso\n","\n","$$\\begin{pmatrix} -1 & 1 \\\\ 1 & -1 \\end{pmatrix} \\binom{x_1}{x_2} = 0  .$$\n","De la primera fila\n","\n","$$-x_1 + x_2 = 0 .$$\n","$$ x_1 = x_2$ (infinitas soluciones). Escoja una, facil\n","$x_1=x_2=1$\n","\n","$$ v = \\binom{1}{1} .$$\n","Toca normalizarlo. La norma del vector $u$ es\n","$$ \\| v \\| = \\sqrt{2} $$\n","De forma que\n","\n","$$ v_1 = \\frac{1}{\\sqrt{2}} \\binom{1}{1} .$$\n","Ahora, vamos para $v_2$.\n","* $\\lambda=1$,\n","\n","\n","\n","\n","\n","$$\\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix} \\binom{x_1}{x_2} = 0  .$$\n","\n","De la primera fila\n","\n","$ x_1 + x_2 = 0$, $x_2=-x_1$, y son infinitos. Tome uno,\n","$x_1 = -1$, $x_2=1$. Toca normalizar, por $\\sqrt{2}$\n","El seguno autovector $v_2$ es\n","\n","$$v_2 = \\frac{1}{\\sqrt{2}} \\binom{-1}{1}  .$$\n","\n","La matriz $V=(v_1 |  v_2)$.\n","\n","$$V = \\begin{pmatrix} 1/\\sqrt{2} & -1/\\sqrt{2}\n","\\\\ 1/\\sqrt{2} & 1/ \\sqrt{2}\n","\\end{pmatrix}  .$$\n","\n","Tambien tenemos a $\\Sigma$, que es una matriz diagonal (en el sentido de que solo los valores a lo largo de la diagonal pueden ser distintos de cero). La diagonal es la linea $a_{ii}$, donde\n","el valor de la fila coincide con el valor de la columna. Es\n","una linea de 45 grados (asumiento que la matriz tiene simbolos\n","del mismo tamanho)\n","\n","\n","\n","pero necesariamente cuadrada. $\\Sigma$ tiene las dimensiones de la matriz original, $m \\times n$, $3 \\times 2$. En la diagonal de $\\Sigma$ estan los **valores singulares** que son las raices cuadradas de $\\lambda_{1,2}$. En este caso\n","$$ \\sigma_1= \\sqrt{3} \\quad , \\quad \\sigma_2 = 1 .$$\n","Entonces\n","\n","$$\\Sigma = \\begin{pmatrix} \\sqrt{3} & 0 \\\\ 0 & 1 \\\\ 0 & 0  \\end{pmatrix}  .$$\n","\n","* Toca buscar los autovectores $u_i$. Una forma es de la ecuacion  $A A^T u_i = \\lambda_i u_i$. Como $A A^T$ es $3 \\times 3$, Se nos complica la vida.\n","\n","En la demostracion del teorema de SVD, s probo que\n","\n","$$ A v_i = \\sigma_i u_i .$$\n","Entonces\n","\n","$$u_i = \\frac{1}{\\sigma_i} A v_i .$$\n","\n"],"metadata":{"id":"sX1V7jPojMTb"}},{"cell_type":"markdown","source":["Veamos para $u_1$\n","\n","$$ 2 /\\sqrt{6} = 2/  \\sqrt{2 \\times 3}= \\sqrt{2/3} $$\n","\n","\n","\n","$$u_1 = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\\\ 0 &1 \\end{pmatrix} \\binom{1/\\sqrt{2} }{1/ \\sqrt{2} }  =  \\begin{pmatrix} \\sqrt{2/3} \\\\ 1/\\sqrt{6}  \\\\ 1/\\sqrt{6} \\end{pmatrix}.$$\n","\n","De igual manera, miremos $u_2$,\n","\n","$$u_2 = \\frac{1}{1} \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\\\ 0 &1 \\end{pmatrix} \\binom{-1/\\sqrt{2} }{1/ \\sqrt{2} }  =\n","\\begin{pmatrix} 0 \\\\ -1/ \\sqrt{2} \\\\ 1/\\sqrt{2} \\end{pmatrix}   $$\n","\n","La matriz $u$ debe ser $3 \\times 3$. Como hallamos el proximo vector $u_3$ ?\n","Toca buscar otra forma. El tercer vector $u_3$ (columna 3 de $U$)\n","debe ser ortogonal a los otros dos.\n","$u_3 = (z_1, z_2, z_3)^T$\n","\n","$$\\langle u_1,  u_3  \\rangle = 0 .$$\n","$$\\langle u_2,  u_3  \\rangle = 0 .$$\n","Escribamos estas dos ecuaciones en $z_1, z_2, z_3$\n","Producto punto\n","\n","$$ \\sqrt{2/3} z_1 + 1/\\sqrt{6} z_2 + 1/\\sqrt{6} z_3 = 0 \\tag{1} $$\n","$$ 0 z_1 - 1/ \\sqrt{2} z_2 + 1/\\sqrt{2} z_3 \\tag{2} $$\n","\n","\n","\n","\n"],"metadata":{"id":"1rinirS5qDt8"}},{"cell_type":"markdown","source":[" Simplifiquemos. Multiplicamos la (1) por $\\sqrt{6}$ y la 2 por $\\sqrt{2}$, quedan entonces:\n","\n","\n"," $$2 z_1 + z_2 + z_3 = 0 $$\n"," $$ 0 z_1 - z_2 + z_3. \\tag{3} $$\n"," Tenemos un parametro libre. Escogemos $z_3=1$\n"," entonces, sumemos las ecuaciones\n","\n"," $$ 2 z_1  + 2 z_3 = 0 \\implies  2 z_1 + 2 = 0 \\implies z_1= -1.$$\n","\n","De (3)\n","$z_2 = z_3 = 1$,\n","entonces\n","\n","$$ u_3 = \\begin{pmatrix} -1 \\\\ 1 \\\\ 1 \\end{pmatrix} .$$\n","no da normalizado pero $\\| u_3 \\| =\\sqrt{3} $\n","\n","$$u_3 = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1 \\\\ 1 \\\\ -1\\end{pmatrix}  .$$\n","\n","de forma que\n","\n","\n","$$ U=\n","\\begin{pmatrix}\n","\\sqrt{2/3} & 0  & -1 /\\sqrt{3} \\\\\n","1/\\sqrt{6} & -1/ \\sqrt{2} & 1 \\sqrt{3} \\\\\n","1 \\sqrt{5} & 1 \\sqrt{2} & 1 \\sqrt{3}\n","\\end{pmatrix}\n","$$"],"metadata":{"id":"z9swFDXrtPW6"}},{"cell_type":"markdown","source":["Recuerden que $A = U \\Sigma V^T$, entonces\n","\n","$$ \\begin{pmatrix} 1 & 1 \\\\ 1 & 0 \\\\ 0 & 1 \\end{pmatrix}=\n","\\begin{pmatrix}\n","\\sqrt{2/3} & 0  & 1 /\\sqrt{3} \\\\\n","1/\\sqrt{6} & -1/ \\sqrt{2} & 1 \\sqrt{3} \\\\\n","1 \\sqrt{5} & 1 \\sqrt{2} & -1 \\sqrt{3}\n","\\end{pmatrix} \\begin{pmatrix} \\sqrt{3} & 0 \\\\ 0 & 1 \\\\ 0 & 0 \\end{pmatrix}\n","\\begin{pmatrix}\n","1/\\sqrt{2} & 1 /\\sqrt{2} \\\\\n","-1/\\sqrt{2} & 1/ \\sqrt{2}\n","\\end{pmatrix} .$$\n","Lo dejo al estudiante verificar que ese triple producto produce la matriz $A$ ."],"metadata":{"id":"BgQ2tK1tulbr"}},{"cell_type":"code","source":["import numpy as np\n","A = np.array([[1,1],[1,0],[0,1]])\n","\n","np.linalg.svd(A)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzYsE7anwaiR","executionInfo":{"status":"ok","timestamp":1724374992184,"user_tz":300,"elapsed":13,"user":{"displayName":"Herman Jaramillo","userId":"11327667299349438387"}},"outputId":"31bb95f6-cafb-4c83-c52f-24662e468d14"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVDResult(U=array([[-8.16496581e-01,  1.85577521e-16, -5.77350269e-01],\n","       [-4.08248290e-01, -7.07106781e-01,  5.77350269e-01],\n","       [-4.08248290e-01,  7.07106781e-01,  5.77350269e-01]]), S=array([1.73205081, 1.        ]), Vh=array([[-0.70710678, -0.70710678],\n","       [-0.70710678,  0.70710678]]))"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["Existe una ambiguedad en el SVD, por que si , por ejemplo $u_1$ es un autvector de $A A^T$ con autovalor $\\lambda$,\n","\n","$$ A A^T u_1 = \\lambda u_1$$\n","$$ A A^T (-u_1) = \\lambda (-u_1)$$\n","incluso si $\\| u_1 \\| = \\| u_2 \\|  = 1$."],"metadata":{"id":"5qiECiSVwn2l"}},{"cell_type":"markdown","source":["**Definicion**: numero de condicion (condition number)\n","Se define\n","\n","$$\\kappa = \\frac{\\sigma_1}{\\sigma_n} .$$\n","$\\sigma_1$ es el mayor de los valores singulares y $\\sigma_n$ el menor (no cero). Mejor dicho $\\sigma_{n+1}=0$ (si la dimension fuera $>n$.\n","Si la matriz es singular $\\sigma_n=0$ y $\\kappa  = \\infty$.\n","\n","Un numero de condicion grande indica **inestabilidad** en la matriz. Hay mucha sensibilidad en el sistema $A x = b$,\n","pequenhos cambios en $A$ implican grandes cambios en $b$.\n","Lo ideal es $\\kappa = 1$. $\\kappa$ de cierta forma representa\n","lo siguiente,  si $\\kappa = 10^n$, $n$ es el numero de cifras de precision que se necesitan (regla del dedo gordo).\n","Un problema con $\\kappa \\gg 1$, se llama \"illed posed\" (mal puesto) y con\n","$k \\approx 1$ well posed (bien puesto).\n","\n","### Cociente de Rayleigh.\n","**Definicion**: Asuma que $A$ es autoadjunta. El **cociente de Rayleigh de $A$ con respecto a $x$ se define como\n","\n","$$R(A,x) = \\frac{x^* A x}{x^* x}= \\frac{\\langle x, A x\\rangle}{\\| x\\|^2}  = \\frac{\\langle Ax, x \\rangle }{ \\| x \\|^2} .$$\n","\n","\n","Tambien piense que\n","\n","\n","$$R(A,x) = \\frac{x^*}{\\| x \\|} A \\frac{x}{\\| x \\|}= u^* A u .$$\n","donde $u=x/\\| x \\|$.\n","\n","**Teorema**: El autovalor mas grande de una matriz auto-adjunta $n \\times n$ es el valor mas grande del cociente de Rayleigh.\n","\n","Prueba: Del teorema espectral sabemos que existe una base\n","$\\{u_1, u_2, \\cdots, u_n  \\}$, ortonormal de autovectores en $\\mathbb{C}^n$. De forma que\n","\n","\n","$$u = \\sum_{i=1}^n \\alpha_i u_i $$\n","\n","$$R(A, u) = u^* A u = \\sum_{i=1}^n \\sum_{j=1}^n \\overline{\\alpha}_i \\alpha_j u_i^* A u_j \\tag{4} .$$\n","Como $u_k$ es vector propio de $A$ con valor propio $\\lambda_k$ tenemos\n","\n","$$ u_i^* A u_j = u_i^* ( \\lambda_j u_j) = \\lambda_j u_i^* u_j = \\lambda_j \\delta_{ij} .$$\n","\n","Insertamos este resultado en la expresion (4)\n","\n","$$R(A, u) = \\sum_{i=1}^n \\sum_{j=1}^n \\overline{\\alpha}_i \\alpha_j u_i^* A u_j = \\sum_{i=1}^n | \\alpha_i |^2 \\lambda_j \\tag{5}  .$$\n","\n","Tenemos que $\\sum_{i=1}^n \\| \\alpha_i \\|^2 = 1$ (pues  $\\| u \\|^2 = 1$.\n","\n","La suma (5) es pun promedio ponderado.  Asumamos que $\\lambda_1$ es el valor propio mas grande.\n","\n","El valor mas grande que pueda esta suma es cuando $| \\alpha_1 |  =1$ y todos los demas\n","$0$.\n","de forma que el valor mas grande de $R(A, u)$ corresponde con\n","el maximo autovalor de $A$.\n","\n","**Teorema** (Cholesky decomposition). Si $A$ es positiva definda, autoadjunta, $A$ se puede escribir como el producto de dos matrices $L$ , $L^*$ de la forma\n","\n","$$ A = L L^*.$$\n","\n","\n","# Proxima clase: Calculo Matricial."],"metadata":{"id":"tdQmHhHnx1iy"}}]}