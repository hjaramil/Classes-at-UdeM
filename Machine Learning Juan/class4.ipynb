{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"class4.ipynb","provenance":[],"authorship_tag":"ABX9TyPouJEUEWJSd9Dwu99235eA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Teorema espectral de las matrices auto-adjuntas: \n","Sea $A$ una matriz autoadjunta $n \\times n$, existe una base ortonormal.\n","\n","$$\\{ x_1, x_2, \\cdots, x_n \\}..$$\n","Estos vectores formados en columna crean la matriz $Q$ y $A$ se puede representar como\n","\n","$$ A = Q \\Lambda Q^*$$\n","donde $\\Lambda$ es una matriz diagonal con los autovalores $\\lambda_i$ correspondientes a los autovectores $x_i$. \n","\n","Prueba: Usamos el principio de induccion matematica. Este es el efecto domino.\n","\n","1.  Tumbas la primera ficha\n","2.  Si cada vez que caiga una ficha $k$ cae la siguiente $k+1$ todas caeran. (para que esto suceda todas las distancias deben ser menor que las alturas).\n","\n","Matematicamente:\n","\n","1. Es valido para $k=1$ (cae la primera ficha).\n","2. Si es valida para $k$ es valido para $k+1$ (la distancia entre las fichas es menor que la altura de la ficha $k$).\n","\n","Se usa para probar teoremas en los enteros, los naturales.\n","\n","\n","Prueba:\n","\n","* $k=1$. Si $k=1$, $k$ es la dimension de la matriz. Si $k=1$, la matriz\n","es un escalar, la llamamos $A$ (una matriz de $1 \\times 1$).\n","\n","Por el teorema fundamental del calculo (ya lo habiamos probado) toda matriz, no importa el orden, tiene una autovalor y un autovector.\n","\n","En este caso $\\det (A - \\lambda I) =0$. En este caso $I=1$, $a-\\lambda=0$,\n","$\\lambda=A$, autovector es cualquier numero, $A = \\lambda 1 = A$.\n","\n","En este caso existe un autovector $x=x_1$, Como la base $\\{ x_1 \\}$\n","es ortonormal por defecto. En este caso $x_1=1$ o $x_1=-1$.\n","\n","* Asumamos que es valido para $k$ y probamos para $k+1$. Es decir\n","asumimos que existe una base ortonormal $B=\\{x_1, x_2, \\cdots, x_k \\}$ de autovectores de la matriz $A$. Veremos que hay uno mas : el $x_{k+1}$.\n","\n","Tenemos que buscarlo por fuera del generado de la base  $B$. \n","\n","Construyamos el espacio ortogonal al generado de $B$.\n","\n","$$ W = \\langle x_1, x_2, \\cdots, x_k \\rangle^{\\perp}$$\n","\n","Vamo a probar que $W$ es **invariante** para $A$, es decir $AW \\subset W$.\n","\n","Asumamos $y \\in AW$, (probaremos que $y \\in W$. \n","Tomemos un $x_i$, $i=1,2, \\cdots, k$ de la base $B$.\n","$y \\in AW$, entonces $y = A x$, $x \\in W$. \n","\n","$$\\langle y , x_i \\rangle = \\langle Ax, x_i \\rangle = \\langle x, A^* x_i \\rangle = \\langle x, A x_i \\rangle = \\langle x, \\lambda x_i \\rangle = \\lambda \\langle x, x_i \\rangle =  0 $$,\n","\n","es decir $y \\in W$, es decir $AW \\subset W$, es decir que $W$ es un ivariante de $A$, es decir, que existe $\\lambda_{k+1}$, $x_{k+1}$ autopar de $A$, y listo, la induccion. Este $x_{k+1}$ es perpendicular a todos $x_i$ (por que esta $\\langle x_1, x_2, \\cdots, x_k \\rangle^{\\perp}$ )\n","Se pueden normalizar todos $u_i = x_i /\\| x_i \\|$, y la base\n","$\\{ u_1, u_2, \\cdots, u_n \\}$ es ortonormal. Construimos\n","\n","\n","$$ Q= [ u_1 | u_2 | \\cdots | u_n ]$$\n","\n","y en la clase anterior ya vimos como\n","\n","$$ A = Q \\Lambda Q^*$$\n","$$ \\Lambda = Q^* A Q $$.\n","\n","Pare que sirve esto?\n","\n","Hay muchas aplicaciones. Solo menciono una.\n","\n","Tome una forma cuadratica. $x=(x_1, x_2, \\cdots , x_n)^T$\n","\n","$$x^T A x = \\sum_{i=1}^n \\sum_{j=1}^n a_{ij} x_i x_j = \\sum_{i=1} \\sum_{j >i} 2 a_{ij}  + \\sum_{i=1}^n a_{ii}^2  $$\n","\n","Contemos operaciones. Tiene $n^2$ terminos, de los cuales $n^2-n$ estan acoplados. Sera que podemos reducir el numero de operaciones ($n^2-1$ sumas y $n^2$ multiplicaciones).\n","\n","Recuerde que como $A$ es autoadjunta (simetrica en $\\mathbb{R}$) y por el teorema anterior $A= Q \\Lambda Q^T$ . \n","\n","$$ x^T A x = x^T Q \\Lambda Q^T x  $$\n","\n","Cambio de variable $y=Q^T x$, $y^T = x^T Q$ y tenemos\n","\n","$$x^T A x = y^T \\Lambda y  $$\n","Como $\\Lambda$ es diagonal\n","\n","$$ x^T A x = \\sum_{i=1}^n \\lambda_i y_i^2 $$\n","\n","\n","\n"],"metadata":{"id":"yB6Q7my_-FF2"}},{"cell_type":"markdown","source":["## Teorema de como multiplicar matrices de distantas formas.\n","\n","Sea $A$ una matriz $m \\times n$ , $B$ una matriz $n \\times p$, y $\\Lambda$ una matriz diagonal con valores $\\lambda_i$ en la diagonal y ceros en todas las otras partes. Entonces:\n","\n","1.  $$ AB = [ AB_1 | AB_2 | \\cdots | A B_p ]  \\quad (1) $$\n","donde $B_i$ es la columna $i$ de la matriz $B$. \n","Esto es muy importante por que si yo solo (por cualquier razon) quiero la comuna $k$ entonces basta con $A B_k$. \n","\n","2. $$ Ax = \\sum_{j=1}^n x_j A_j$$\n","donde $x =(x_1, x_2, \\cdots, x_n)^T \\in \\mathbb{C}^n$, y $A_j$ es la columna $j$ de la matriz $A$. \n","Es decir, el producto $Ax$ es la suma ponderadas de las columnas de $A$ con los pesos dados por los $x_j$. Tambien esto quiere decir\n","$Ax \\in \\mathcal{R}(A)$. Espacio columna de $A$. \n","\n","3. Si $p \\ge n$,\n","\n","$$ A \\Lambda =[ \\lambda_1 A_1 | \\lambda_2 A_2 | \\cdots | \\lambda_n A_n | 0_n | 0_{n+1} | \\cdots 0_p ] $$\n","\n","si $p<n$,\n","$$ A \\Lambda =[ \\lambda_1 A_1 | \\lambda_2 A_2 | \\cdots | \\lambda_n A_n ]  \\quad , \\quad (2) $$\n","\n","4. Si $u_i$ sos vectores columnas de una matriz $U$ , $m \\times m$ entonces\n","\n","\n","$$U^* b = \\begin{pmatrix}  u_1^*b \\\\ u_2^*b \\\\ \\vdots \\\\ u_m^* b \\end{pmatrix}  $$ donde $b \\in \\mathbb{C}^n$.\n","\n","Solo prueba el primero.\n","Sea $C=AB$, \n","\n","$$c_{ij} = \\sum_{k=1}^n a_{ik} b_{kj} $$\n","\n","Tomemos la columna $j$ de la derecha de la ecuacion (1). \n","\n","$$(AB_j)_i = \\sum_{k=1}^n a_{ik} b_{ij} = c_{ij}$$\n","\n","\n","\n","\n","\n"],"metadata":{"id":"vikZPX-NR-Xg"}},{"cell_type":"code","source":["9:10 am"],"metadata":{"id":"HR8hZqAUUqT5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No todas las matrices son autoajuntas (en realidad casi ninguna). Entonces podemos hacer \"diagonalizacion\" para matrices no autoadjuntas? Resp. Si, en algunos casos.\n","\n","Asuamos que la matriz $A$ (cuadrada) en $n \\times n$, tiene exactmente $n$ autovectores linealmente independientes.\n","(uno podria hacer un Gram-Schmidth, pero no)\n","Entonces construyamos los siguiente: Sean $P_i$, $i=1,2, \\cdots, n$\n","los autovectores de $A$. Sea $P$ la matriz con columnas $P_i$. \n","\n","$$ A P_i = \\lambda_i P_i $$\n","Aca usamos el teorema anterior (ecuacion (2)) \n","\n","$$[\\lambda_1 P_1 | \\lambda_2 P_2 | \\cdots | \\lambda_n P_n] = P \\Lambda$$\n","y con la (1)\n","\n","$$AP  = P \\Lambda $$,\n","\n","Multiplicamos por $P^{-1}$ a derecha\n","\n","$$APP^{-1}  = P \\Lambda  P^{-1}$$,\n","\n","$$ A = P \\Lambda P^{-1} \\quad , \\quad (3) $$\n","\n","Ahora bien, multiplique a izquierda por $P^{-1}$ \n","\n","$$ \\Lambda = P^{-1} A P $$\n","\n","A esto se le llama **diagonalizacion** y decimos que $A$ es diagonalizable. No todas las matrices (cuadradas) son diagonalizables. \n","Cuando no lo son, lo mas cerca que podemos estar de una diagonal es usando [la forma canonica de Jordan](https://en.wikipedia.org/wiki/Jordan_normal_form).  Esto no lo trabajamos en este curso.\n","\n","\n","Aplicacion. Como elevar una matriz a una potencia.\n","\n","$$ A^k = P \\Lambda^k P^{-1} \\quad , \\quad (4) $$\n","cuando $A$ es diagonalizable.\n","\n","Probemos esto. Por induccion.\n","\n","1. $k=1$, es verdadd por la ecuacion (3)\n","2. Asumimos que es cierto para $k$ y lo probamos para $k+1$.\n","\n","Generalmente las pruebas por induccion se hacern buscando recursividad.\n","\n","\\begin{eqnarray}\n","A^{k+1} &=& A^k A  \\quad \\text{por recursividad de la potencia} \\\\\n","&=& (P \\Lambda^k P^{-1})A \\quad  \\text{por ecuacion 4, hipotesis de induccion} \\\\\n","&=& (P \\Lambda^k P^{-1}) (P^{-1} \\Lambda P^{-1}) \\quad  \\text{por ecuacion 3} \\\\\n","&=& (P \\Lambda^k) (P^{-1} P)(\\Lambda P^{-1}) \\quad \\text{asociatividida prod. mat} \\\\\n","&=& P \\Lambda^k I \\Lambda P^{-1} \\quad \\text{ $PP^{-1}=I$}  \\\\\n","&=& P \\Lambda^{k+1} P^{-1} \n","\\end{eqnarray}\n","Se prueba la hipotesis de induccion.\n","\n","Definicion [Positiva Definida]. Sea $A$ una matriz autoadjunta. Se dice que es **positiva definida** si todos sus autovalres son positivos, **negativa definida** si todos sus autovalores son negativos, **no negativa definida** si todos sus autovalres son positivos o 0.\n","\n","Se puede probar (es un problema para los estudiantes) que esta definicion es equivalente a la siguiente:\n","\n","\n","Una matriz $A \\in \\mathbb{C}^{n \\times n}$ autoadjunta es positiva definida si $\\forall x \\in \\mathbb{C}^n$, $x^* A x \\ge 0$. \n","Que es negativa definida sis $\\forall x \\in \\mathbb{C}^n$ $x^* A x < 0$, y no-negativa definida si $\\forall x \\in \\mathbb{C}^n$, $x^* A x \\ge 0$,.\n","\n","Teorema: Si $A$ es positiva definida, existe $A^{-1}$ y esta a su vez es tambien positiva definida,\n","\n","\n","\n","### Teorema de SVD. Singular Value Decomposition.\n","Sea $A \\in \\mathbb{C}^{m \\times n}$, (no hay mas hipotesis), entonces\n","existen matrices $U \\in \\mathbb{C}^{m \\times m}$, $V \\in \\mathbb{C}^{n \\times n}$ y $\\Sigma \\in \\mathbb{R}^{m \\times n}$. Tales que\n","\n","\n","$$ A = U \\Sigma V^*$$.\n","$\\Sigma$ es diagonal (ceros en todas partes, excepto, posiblemente en la diagonal.\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"slH76WfZfeUj"}},{"cell_type":"markdown","source":["Prueba: Debida a Cornelius Lanczos (Hungaro).\n","\n","Constrruya la matriz $S$\n","\n","\\begin{eqnarray}\n","S= \\begin{pmatrix}\n","0 & | & A \\\\\n","-- & -- &--  \\\\\n","A^* & | & 0 \n","\\end{pmatrix}\n","\\end{eqnarray}\n","Como se ve $S \\in \\mathbb{C}^{(m+n) \\times (m+n)}$. Es autoadjunta,\n","como es autoadjunta podemos aplicar el teorema espectral. Existen \n","autovectores mutuamente ortogonales tales que\n","\n","$$ S w_i = \\lambda_i w_i  \\quad (5) \\quad  $$\n","\n","Dividamos los $w_i$ como sigue:\n","\n","\\begin{eqnarray}\n","w_i = \\begin{pmatrix}\n","u_i \\\\ v_i \n","\\end{pmatrix}\n","\\end{eqnarray}\n","con $u_i \\in \\mathbb{C}^m$ y $v_i \\in \\mathbb{C}^n$. \n","Reescribimos la ecuacion (5).\n","\n","\\begin{eqnarray}\n","A^* u_i &=& \\lambda_i v_i \\\\\n","\\quad \\quad  && \\quad \\quad  (6) \\\\\n","A v_i &=& \\lambda_i u_i \n","\\end{eqnarray}\n","los $\\lambda_i \\in \\mathbb{R}$. \n","\n","Truco: Multiplicamos la primera por $A$ y la segunda por $A^*$.\n","\n","\\begin{eqnarray}\n","A A^* u_i = \\lambda_i A v_i = \\lambda_i^2 u_i  \\\\\n","A^* A v_i = \\lambda_i A^* u_i = \\lambda_i^2 v_i \n","\\end{eqnarray}\n","De forma que $u_i$ son autovectores de $A A^*$ con autovalor positivo $\\lambda_i^2$, meintras que los $v_i$ son autovectores de $A^* A$ con los mismos autovalores (positivos).\n","\n","$$ A A^* \\in \\mathbb{C}^{m \\times m}$$\n","$$ A^* A \\in \\mathbb{C}^{n \\times n}$$.\n","\n","Algunos autovalores podrian ser 0, Ordenamos de mayor a menor todos los $\\lambda_i^2$, $\\lambda_1^2 \\ge \\lambda_2^2 \\ge \\cdots \\lambda_r^2 \\ge 0 =\\cdots = 0$. Sea $r$ el indice maximo hasta donde , de ahi en adelante, todos los $\\lambda_i^2 = 0$.\n","\n","Construyamos dos matrices. La matriz de autovectores $u_i$ que la llamamos $U$, y la matriz de autovectores $v_i$ que la llamamos $V$.\n","Ahora, llamamos $U_r$ a la matriz de autvectores desde $u_1, \\cdots, u_r$,\n","y $U_0$ a la matriz de autovectores $u_{r+1}, \\cdots, u_m$.\n"," llamamos $V_r$ a la matriz de autvectores desde $v_1, \\cdots, v_r$,\n","y $V_0$ a la matriz de autovectores $v_{r+1}, \\cdots, v_m$.\n","\n","Tenemos entonces que si $\\Lambda_r$ es una matriz cuadrada de $r \\times r$ con los $\\lambda_i = \\sqrt{\\lambda_i^2}$.  Reescribimos las ecuaciones (6) en terminos de $U_r,  U_0, V_r, V_0$,\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"arqw8eqCqPai"}},{"cell_type":"markdown","source":[],"metadata":{"id":"73P8dsiSzgKw"}},{"cell_type":"markdown","source":["De las ecuaciones (6) y el teorema de multiplicacion de matrices\n","\n","\\begin{eqnarray}\n","A^* U_r &=& V_r \\Lambda_r \\quad , \\quad A^* U_0 = 0 \\\\\n","A V_r &=&U_r \\Lambda_r \\quad , \\quad AV_0 = 0  \\quad (7)\n","\\end{eqnarray}\n","\n","Definimos \n","\n","\\begin{eqnarray}\n","\\Sigma = \\begin{pmatrix}\n","\\Lambda_r  & | & 0 \\\\\n","-- & -- &--  \\\\\n","0 & | & 0 \n","\\end{pmatrix}\n","\\end{eqnarray}\n","\n","En bloque las ecuaciones (7) en bloque\n","\n","$$ A V = U \\Sigma $$.\n","\n","Multiplicamos ambos lados por $V^*$ (recuerde que $V^*=V^{-1}$) \n","\n","$$ A V V^* = U \\Sigma V^*$$\n","Ahora, como $V V^* =I $ entonces\n","\n","$$ A = U \\Sigma V^*$$\n","Esto concluye la prueba. \n","Los $\\lambda_i^2 \\ge 0$. Le sacamos la raiz quadrada y los llamos\n","$\\sigma_i = \\sqrt{\\lambda_i^2}$.  A estos los llamamos **valores singulares** \n","\n"],"metadata":{"id":"VVg3OIsdumuM"}},{"cell_type":"markdown","source":["Ejemplo: Halle la SVD de la matriz:\n","\n","$$ A =  \\begin{pmatrix} 1 & 0 & 3 \\\\ 1 & 2 & 4 \\end{pmatrix}$$ \n","\n","Solucion:\n","\n","*  Toca construir $A^*A$ y $A A^*$\n","\n","*  Encontrar los autopares de $A^* A$ (estos son los $v_i$) y de  $A A^*$ estos son los $u_i$, toca normalizarlos, y ponerlos en orden.\n","Organize los $\\sigma_i = \\sqrt{\\lambda_i^2}$ en orden descendente, y los autovectores deben coincidir en el oden para definir las matrices\n","$U$, $V$. n\n","\n","* Construya las matrices $U$, $V$ y $\\Sigma$. "],"metadata":{"id":"NczDl9bozkCX"}},{"cell_type":"markdown","source":["1. \n","$$ A A^* =  \\begin{pmatrix} 1 & 0 & 3 \\\\ 1 & 2 & 4 \\end{pmatrix}\n"," \\begin{pmatrix} 1 & 1 \\\\ 0 & 2 \\\\ 3 & 4 \\end{pmatrix} = \\begin{pmatrix} 10 & 13 \\\\ 13 & 21\\end{pmatrix} $$\n","\n","$$ A^* A= \\begin{pmatrix} 1 & 1 \\\\ 0 & 2 \\\\ 3 & 4 \\end{pmatrix}\n","\\begin{pmatrix} 1 & 0 & 3 \\\\ 1 & 2 & 4\\end{pmatrix} = \\begin{pmatrix} 2 & 2 & 7 \\\\ 2 & 4 & 8 \\\\ 7 & 8 & 25\\end{pmatrix} $$\n","\n","\n","Tarea encontrar los autovalores de $A A^*$. Encuentre el polinomio caracteristico. Es cuadratico, y las raices son\n","\n","$$\\lambda_1^2 = \\frac12 ( 31 + \\sqrt{797}) \\approx 29.62  \\quad , \\quad \\lambda_2^2 = \\frac12 (31 - \\sqrt{797} )\\approx 1.38 $$\n","\n","Con estos autovalores encuentra los autovectores. Para $\\lambda_1^2$.\n","\n","(toca justificarlo).\n","\n","$$ U_1 = \\begin{pmatrix} 0.55 \\\\ 0.83 \\end{pmatrix}\n","\\quad , \\quad U_2 = \\begin{pmatrix} -0.83 \\\\ 0.55 \\end{pmatrix} $$\n","\n","Para $\\lambda_2^2$, \n","\n","\n","$$ V_1 = \\begin{pmatrix} 0.25 \\\\ 0.31 \\\\ 0.92 \\end{pmatrix}\n","\\quad , \\quad V_2 = \\begin{pmatrix} -0.24 \\\\ 0.94 \\\\ -0.24  \\end{pmatrix}  \\quad , \\quad V_3 = \\begin{pmatrix} 0.92 \\\\ -0.24 \\\\ 0.31 \\end{pmatrix} $$\n","\n","De forma que:\n","\n","\n","\n","\\begin{eqnarray*}\n","    A = U \\Sigma V^T = \n","    \\begin{pmatrix} \n","      0.55 & -0.83 \\\\\n","      0.83 & 0.55\n","    \\end{pmatrix}\n","    \\begin{pmatrix}\n","      5.44 & 0 & 0  \\\\\n","      0 & 1.17 & 0 \n","    \\end{pmatrix}\n","    \\begin{pmatrix}\n","      0.25 & 0.31 & 0.92 \\\\\n","      -0.24 & 0.94 & -0.24 \\\\\n","      -0.94 & -0.16 & 0.31\n","    \\end{pmatrix} \\; .\n","  \\end{eqnarray*}\n"],"metadata":{"id":"Tueu_0CG0jFa"}}]}