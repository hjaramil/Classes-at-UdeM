{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYni+/mZW9mAao1L8kpQ0H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Teorema espectral para matrices autoadjuntas.\n","## Caso de autovalores no repetidos\n","\n","Teorema: Si una matriz $A$ es autoadjunta, con  autovalores **distintos** entonces\n","\n","1. Los autovalores son reales.\n","2. Los autovectores son ortogonales.\n","\n","Prueba:\n","Una nota inicial.\n","\n","Dada la siguiente forma cuadratica $\\langle A x, b \\rangle $.\n","$$\\langle Ax, b \\rangle = (Ax)^* b = x^* A^* b = x^*(A^*b) = \\langle x, A^* b \\rangle  \\tag{0} .$$\n","\n","Probemos 1.\n","Asuma que los autovalores de $A$ son $\\lambda_j$ correspondientes a autovectores $u_j$. Sin perdida de generealidad podemos considerarlos como normalizados $\\| u_j \\| = 1$. Consideremos la siguiente forma cuadratica.\n","\n","\n","$$\\langle A u_j, u_j \\rangle = \\langle \\lambda_j u_j, u_j \\rangle = \\overline{\\lambda_j} \\langle u_j , u_j \\rangle = \\overline{\\lambda_j} \\tag{1} .$$\n","\n","\n","Ahora como $\\langle A u_j, u_j \\rangle = \\langle u_j, A^* u_j \\rangle $,\n","Ademas recuerde que $A^* = A$ (por ser autoadjunta).\n","\n","Entonces,\n","\n","$$\\overline{\\lambda} = \\langle u_j , A^* u_j \\rangle = \\langle u_j, A u_j \\rangle = \\langle u_j , \\lambda_j u_j \\rangle = \\lambda_j \\langle u_j, u_j \\rangle = \\lambda_j  \\tag{2} .$$\n","\n","De la la ecuacion 2 tenemos que\n","\n","$\\lambda = \\overline{\\lambda}$.\n","O sea que $\\lambda \\in \\mathbb{R}$.\n","\n","\n","Probemos 2.\n","Es decir probemos que si $u,v$ son dos autovectores correspondientes a dos autovalores distintos, entonces $\\langle u, v \\rangle = 0.$\n","\n","Comencemos con la forma cuadratica\n","\n","$$ \\langle A u , v \\rangle = \\langle \\lambda_1 u, v \\rangle = \\lambda_1 \\langle u, v \\rangle  \\tag{3} .$$\n","\n","\n","Ahora como $A$ es autoadjunta $A= A^*$, de forma que, recuerde la ecuacion (0),\n","\n","$$ \\langle Au, v \\rangle = \\langle u, A v \\rangle = \\langle u, \\lambda_2 v \\rangle = \\lambda_2 \\langle u, v \\rangle  \\tag{4} .$$\n","o\n","De las ecuaciones (3) y (4)\n","\n","$$\\lambda_1 \\langle u, v \\rangle = \\lambda_2 \\langle u, v \\rangle .$$\n","pasando a restar\n","\n","$$\\lambda_1 \\langle u, v \\rangle - \\lambda_2 \\langle u, v \\rangle = 0 .$$\n","Es decir\n","\n","$$(\\lambda_1 - \\lambda_2) \\langle u, v \\rangle = 0 .$$\n","Pero como $\\lambda_1 \\ne \\lambda_2$,\n","\n","$\\langle u, v \\rangle = 0$, es decir $u,v$ son **ortogonales**."],"metadata":{"id":"DEiB6VZFKYGE"}},{"cell_type":"markdown","source":["Esto para que sirve?\n","\n","Asuma $A \\in \\mathbb{C}^n$, asuma que **todos** los autovalores son distintos, de forma que se tienen $n$ autovectores $x_i$, $i=1,2, \\cdots , n$ ortogonales (linealmente independientes). Tenemos la relacion $$ A x_i = \\lambda_i x_i$$\n","donde $\\lambda_i$ es el autovalor $i$.  Ahora bien como todos son ortogonales entre si, $x_i^* x_j = \\delta_{ij}$, entonces\n","\n","Observe la siguiente forma cuadratica\n","$\\langle x_i , A x_j \\rangle $\n","que es,\n","$$x_i^* A x_j =  x_i^* (\\lambda_j x_j) = \\lambda_j x_i^* x_j = \\lambda_j \\delta_{ij} .$$\n","\n","La matriz $Q$ es la matriz de columnas $x_i$, la matriz $\\Lambda$ es la matriz diagonal con elementos $\\lambda_i$\n","\n","Escribimos el resultado anterior de forma matricial como\n","\n","\n","$$ Q^* A Q = \\Lambda . \\tag{5}$$"],"metadata":{"id":"6TmhD1j_nbII"}},{"cell_type":"markdown","source":["El resultado anterior es importante y lo podemos escribir de otra forma.\n","Multipliquemos a izquierda por $Q$\n","\n","$$Q Q^* A Q = Q \\Lambda .$$\n","$$I A Q = Q \\Lambda .$$\n","$$ A Q = Q \\Lambda .$$\n","Multiplicamos a derecha por $Q^*$\n","\n","$$ A Q Q^* = Q \\Lambda Q^*.$$\n","$$ A I = Q \\Lambda Q^*.$$\n","$$ A  = Q \\Lambda Q^*. \\tag{6}$$\n","\n","Las ecuaciones (5) y (6) son la representacion espectral de la matriz $A$ en terminos del **espectro**. El espectro es el conjunto de autovalores.\n","\n","Que pasa si hay autovalores **repetidos**.\n","En este caso **tambien** se cumplen las ecuaciones (5), (6). La prueba de esto esta en las notas de clase que les comparti en el aula virtual."],"metadata":{"id":"SFB9iFahAH84"}},{"cell_type":"markdown","source":["Para que diablos sirven las ecuaciones (5) y (6)?\n","\n","Vamos a ver varias aplicaciones.\n","\n","* Considere la siguiente forma cuadratica para una matriz $A \\in \\mathbb{R}^{n \\times n}$  y simetrica.\n","Considere tambien un vector $x \\in \\mathbb{R}^n$. Las componentes de $x$ son $x_i$, $i=1,2, \\cdots, n$.\n","\n","La siguiente forma cuadratica\n","\n","$$ \\langle x, Ax \\rangle  = x^T A x = \\sum_{i=1}^n \\sum_{j=1}^n a_{ij} x_i x_j .$$\n","\n","tiene $n^2$ terminos, de los cuales , si $A$ es simetrica entonces\n","$n^2 - n$ (quitando la diagonal) estan acoplados.\n","\n","\n","Para que sirven las ecuaciones (5) y (6)?\n","\n","Usemos la ecuacion (6) $A=Q \\Lambda Q^T$.\n","\n","$$x^T A x = (x^T Q) \\Lambda (Q^T x) .$$\n","Llamemos $y^T=x^T Q$, $y = Q^T x$.\n","\n","\n"],"metadata":{"id":"pwVxhEngrKso"}},{"cell_type":"markdown","source":["Entonces\n","\n","$$x^T A x =  y^T \\Lambda y = \\sum_{i=1}^n \\lambda_i y_i^2.$$"],"metadata":{"id":"4WunAzfztZEh"}},{"cell_type":"markdown","source":["Tenemos solo $n$ terminos. Bajamos de $n^2$ ."],"metadata":{"id":"eIhOx3xftZOK"}},{"cell_type":"markdown","source":["Teorema de multiplicacion de matrices.\n","\n","Sean $A$ una matriz $m \\times n$, $B$ una matriz $n \\times p$, $x$ un vector en $n$ dimensiones, $\\Lambda$ una matriz diagonal $n \\times p$  una matriz diagonal con valores $\\lambda_i$ en la diagonal y ceros en cualquier otra posicion.\n","\n","1.\n","\n","$$ AB = [ AB_1 | AB_2 | \\cdots | AB_p ]. \\tag{7}$$\n","donde $B_j$ es la columna $j$ de $B$.\n","Esta propiedad es muy importante. En ocaciones necesitamos calcular la columna $j$ de un producto de matrices. No tenemos que hacer todo el producto de matrices, solo $AB_j$.\n","\n","2.\n","$$ Ax = \\sum_{j=1}^n x_j A_j . \\tag{8} $$\n","donde $A_j$ es la $j$ columna de $A$. Esto es importante por que estamos\n","diciendo que $Ax \\in \\mathcal{R}(A)$.\n","\n","3.\n","Si $p > n$\n","\n","$$ A \\Lambda = \\left [ \\lambda_1 A_1  | \\lambda_2 A_2 \\cdots \\lambda_n A_n  |  O_{n+1} | \\cdots | 0_p \\right ] .$$\n","\n","donde tenemos $p-n$ columnas de ceros. Aca $0_j$ es la $j$ columna de ceros.\n","Si $n \\ge p$\n","\n","$$ A \\Lambda = \\left [ \\lambda_1 A_1  | \\lambda_2 A_2 \\cdots \\lambda_p A_p  \\right ]  \\tag{9} .$$\n","\n","\n","4.\n","Si $u_i$ son vectores columna de una matriz $m \\times m$ y $b \\in \\mathbb{C}^m$ entonces:\n","\n","$$ U^* b = \\begin{pmatrix} u_1^* b \\\\ u_2^* b  \\\\ \\vdots \\\\ u_m^* b \\end{pmatrix} . \\tag{10}$$\n","\n","\n","**Prueba**:\n","\n","1. Sea $C=AB$ entones, por definicion de producto de matrices\n","\n","\n","$$c_{ij} = \\sum_{k=1}^n a_{ik} b_{kj} .$$\n","\n","Tomemos la columna $j$ de la expresion  (7) y de alli la componente $i$\n","\n","$$(AB_j)_i = \\sum_{k=1}^n a_{ik} b_{kj} .$$\n","pero est es lo mismo que $c_{ij$ de forma se prueba 1.\n"],"metadata":{"id":"CJNKVWjBurtN"}},{"cell_type":"markdown","source":["2. Probamos la ecuacion 8.\n","De igual forma, consideremos la componente $i$ del vector $Ax$\n","\n","$$ (Ax)_i = \\sum_{j=1}^n a_{ij} x_j = \\left (  \\sum_{j=1}^n x_j A_j  \\right )_i  .$$\n","esta es precisamente la ecuacion (8).\n","\n","3. Solo probamos la ecuacion (9).\n","Veamos\n","\n","\\begin{eqnarray}\n","A \\Lambda &=& \\left [  A \\Lambda_1 | A \\Lambda_2 | \\cdots | A \\Lambda_p  \\right ] \\quad \\text{usando la ecuacion (7)} \\\\\n","&=& \\left [ \\lambda_1 A_1 | \\lambda_2 A_2 | \\cdots | \\lambda_p A_p  \\right ]\n","\\end{eqnarray}\n","y esto es lo que queriamos probar. Aclaracion $\\Lambda_j$ es un vector columna con $\\lambda_j$ en la $j$ fila y 0 en las demas.\n","El caos $p>n$ no lo mostramos (se deja como ejercicio).\n","\n","4. Probamos la ecuacion (10).\n","\n","La fila $i$ del producto $U^* b$ esta dada por $(U^* b)_i$ como\n","\n","\n","$$ (U^* b)_i = \\sum_{j=1}^m \\overline{u_{ji}} b_j = \\langle u_i, b \\rangle  = u_i b^*.$$\n","Esto es lo que deberiamos probar, la ecuacion (10) donde $i=1,2, \\cdots, n$\n","\n"],"metadata":{"id":"9_y-pF5XygZn"}},{"cell_type":"markdown","source":["### Diagonalizacion de Matrices.\n","Es otra forma de factorizar matrices en tres factores, como la espectral pero\n","no necesariamente hay ortogonalidad.\n","\n","Asumamos que $A$ no es autoadjunta (no hay ortognalidad en sus autovectores).\n","Asumamos, tambien, que los autovectores son linealmente independientes(li).\n","sean $P_i$ los $n$ autovectores de la matriz $A$ (son li). Los autovalores son $\\lambda_i$. Entonces, por definicion autovector/valor\n","\n","\n","$$ AP_i = \\lambda_i P_i .$$\n","Usamos las ecuaciones de arriba, llevamos esto a forma matricial\n","\n","\n","$$ AP = P \\Lambda  \\tag{11} $$\n","donde usamos las ecuaciones (7) y la (9)\n","\n","En la (11) multiplicamos a izquierda por $P^{-1}$ (existe)\n","\n","$$ P^{-1} AP =  \\Lambda  \\tag{12} $$\n","\n","En la (11) multiplicamos a derecha por $P^{-1}$ (existe)\n","$$ APP^{-1} = P \\Lambda   P^{-1}\\tag{11} $$\n","es decir\n","$$ A = P \\Lambda   P^{-1}\\tag{12} $$"],"metadata":{"id":"JZvW46251QMD"}},{"cell_type":"markdown","source":["La ecuacion 12 es otra factorizacion donde $A$ es el producto de\n","tres matrices. La del centro es diagonal. Ojo que $P, P^{-1}$ no son\n","necesariamente ortogonales.\n","\n","A esto se llama **diagonalizacion**. Decimos que la matriz $A$ con autovectores li es **diagonalizable.\n","\n","**Aplicacion:** Potencia de una matriz diagonalizable.\n","Pruebe que para una matriz $A$ diagonalizable $A^k = P \\Lambda^k P^{-1}$\n","\n","\n","Prueba por induccion:\n","\n","* Probemos para $k=1$, este es el caso de la ecuacion (12)\n","\n","$$ A = P \\Lambda   P^{-1} $$\n","\n","Asumaos que se cumple para $k$, y esto implica que se cumple para $k+1$,\n","\n","\n","\\begin{eqnarray}\n","A^{k+1} &=& A^k A  \\\\\n","&=& (P \\Lambda^k P^{-1}) (P \\Lambda P^{-1}) \\\\\n","&=& P \\Lambda^k (P^{-1} P) \\Lambda P^{-1} \\\\\n","&=& P \\Lambda^{k+1} P^{-1}\n","\\end{eqnarray}"],"metadata":{"id":"exSbuLIC26Pe"}},{"cell_type":"markdown","source":["Proxima clase:\n","* Definimos matrices positivas definidas\n","* Probamos el teorema de SVD: Singular Value Decomposition (ejemplos)\n","Este teorema es la clave de reduccion de dimensionalidad y PCA."],"metadata":{"id":"0SiJIBDO4leL"}}]}